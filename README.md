The project focuses on classifying nature sounds using different deep learning methods. It deals with classifying nature sounds accurately by transforming audio signals into time-frequency images, a process that enables CNNs to capture intricate patterns in the data. The time frequency images are categorized into any one of the nine classes such as rain, sea waves, crackling fire, crickets, chirping birds, wind, pouring water, water flushing and thunderstorm. This project uses deep learning models such as VGGNet, ResNet and EfficientNet to perform nature sound classification. Also, this project applies a vanilla CNN model to the dataset and compares it with pre-trained deep learning models. 
